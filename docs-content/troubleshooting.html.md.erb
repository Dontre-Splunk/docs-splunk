---
title: Troubleshooting Splunk Firehose Nozzle for PCF
owner: Partners
---

This topic describes how to troubleshoot Splunk Firehose Nozzle for PCF.

## <a id='architecture'></a> Architecture Overview

The Splunk Firehose Nozzle for PCF has been developed as a Cloud Foundry Elastic Runtime application.
The nozzle subscribes to the Cloud Foundry Loggregator endpoint and writes events to an external Splunk environment.

![Report Example: Basic Nozzle Architecture](images/overview.png)
<strong><center>Figure 1: Basic Nozzle Architecture</center></strong>

<strong>Inside each nozzle:</strong>

* A Golang routine is subscribed to collect events from the PCF Loggregator endpoint.
* An in memory queue will buffer events to make available for multiple Splunk HTTP Event Collector clients.
* The Splunk HTTP Event Collector clients run as their own Golang Routines consuming events from the queue enriching PCF events by attaching
metadata fields.
* Finally the events are batched together and sent to Splunk via the HEC Endpoint in the Splunk environment.

![Report Example: Internal Nozzle Architecture](images/nozzle-internals-large.png)
<strong><center>Figure 2: Nozzle Internal Architecture</center></strong>




Before troubleshooting, it is useful to understand what the tile installs.


## <a id='walkthrough'></a> Troubleshooting Walkthrough

The following assumes you have access to Splunk to run basic searches against index `_internal`
and the user-specified index for Firehose events.

### 1. Ensure Splunk indexer(s) are listening to data on configured port

  Search internal logs of indexer(s), specifically the TCP input processor, as follows:

  ```
  index=_internal sourcetype=splunkd component=TcpInputProc 
  ```

  A correct setup shows a following event at startup time:

  *10-13-2016 17:31:16.226 +0000 INFO  TcpInputProc - Creating fwd data Acceptor for IPv4 port 9997 with SSL*

### 2. Ensure Splunk nozzle is connected to Splunk indexer(s):

  Search internal logs of nozzle, specifically the TCP output processor, to confirm Splunk nozzle is correctly forwarding:

  ```
  index=_internal host="splunk-nozzle_*" sourcetype=splunkd component=TcpOutputProc
  ```
  A correct setup shows an event as follows:

  *11-04-2016 20:24:13.702 +0000 INFO  TcpOutputProc - Connected to idx=<redacted>:9997 using ACK.*

  If no such event is found, then no data is being forwarded from nozzle. 
  This can be due to mis-configured indexer(s) firewall, or mis-configured SSL settings of either nozzle (forwarder) or indexer(s). 
  Search internal logs of Splunk indexer(s) for any errors:

  ```
  index=_internal sourcetype=splunkd component=TcpInputProc ERROR
  ```

  An example error would be:
  *11-03-2016 22:23:00.046 +0000 ERROR TcpInputProc - Error encountered for connection from src=<redacted>:55713. error:140760FC:SSL routines:SSL23_GET_CLIENT_HELLO:unknown protocol*

  Whether you are using self-signed certificates or certificates signed by a third party, ensure to follow these [instructions](http://docs.splunk.com/Documentation/Splunk/6.5.1/Security/HowtoprepareyoursignedcertificatesforSplunk) to provide your signed certificates details in correct format when configuring the tile. For more details on troubleshooting and validating your forwarder/receiver connection, see:

  * http://docs.splunk.com/Documentation/Splunk/6.5.1/Forwarding/Receiverconnection
  * http://docs.splunk.com/Documentation/Splunk/6.5.1/Security/Validateyourconfiguration
  * http://docs.splunk.com/Documentation/Splunk/6.5.1/Security/Troubleshootyouforwardertoindexerauthentication

### 3. Ensure Splunk nozzle is forwarding events from the Firehose:

  Search app logs of nozzle to confirm correct behavior:

  ```
  sourcetype="cf:splunknozzle"
  ```

  A correct setup logs number of Firehose events logged as JSON objects, for example:

  ```json
  {
    "ip": "localhost",
    "job": "splunk-nozzle",
    "job_index": "-1",
    "log_level": 1,
    "logger_source": "splunk-nozzle-logger",
    "message": "splunk-nozzle-logger.Posting 635 events",
    "origin": "splunk_nozzle"
  }
  ```

  Search app logs of nozzle for any errors:

  ```
  sourcetype="cf:splunknozzle" data.error=*
  ```

  Errors are logged with corresponding message and stacktrace.

### 4. Check for dropped events due to HTTP Event Collector availability:

  As the Splunk Firehose Nozzle is sending data to splunk via HTTPS using the HTTP Event Collector it is also susceptible to any network issues across the network path from point to point. Run the following search to determine if Splunk has indexed any events indicating issues with the HEC Endpoint.


  ```
  sourcetype="cf:splunknozzle" "dropping events"
  ```

### 5. Check for data loss inside the Splunk Firehose Nozzle :


  If "Event Tracing" is enabled, extra meta-data will be attached to events allowing searches to calculate the percentage of data loss inside the Splunk Firehose Nozzle, if any.

  Each instance of the Splunk Firehose Nozzle will run with a randomly generated UUID. The below query will display the message success rate for each UUID.

  ```
  index=main | stats count as total_events , max(nozzle-event-counter) as max_number by uuid | eval success_percentage=(total_events/max_number) * 100 | table success_percentage
  ```

