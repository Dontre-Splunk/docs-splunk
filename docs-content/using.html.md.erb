---
title: Using Splunk Firehose Nozzle for PCF
owner: Partners
---

This topic describes how to use Splunk Firehose Nozzle for PCF. After installing & configuring Splunk Firehose Nozzle for PCF, PCF operators can then navigate in the browser to the URL of their existing Splunk Enterprise deployment to immediately search, report, visualize and alert on PCF Firehose data.

The following assumes basic familiarty on how to run searches, save reports, and create dashboards in Splunk Enterprise. If you're new to Splunk, start with the [Search Tutorial](https://docs.splunk.com/Documentation/Splunk/6.5.0/SearchTutorial/WelcometotheSearchTutorial) which will show you how to search data and create simple dashboards.

For a starter sample dashboard for operational intelligence, you can [use Splunk Add-on for Cloud Foundry](#add-on) which also includes many pre-built panels and reports to help you quickly build your own custom dashboards to monitor the health of your foundation and the performance of your applications.

##<a id='search'></a>Search Firehose Data

The firehose event types forwared by the Splunk Nozzle are assigned the following Splunk sourcetypes by default:

  PCF Firehose event type | Splunk sourcetype
  --- | ---
  Error | `cf:error`
  HttpStartStop | `cf:httpstartstop`
  LogMessage | `cf:logmessage`
  ContainerMetric | `cf:containermetric`
  CounterEvent | `cf:counterevent`
  ValueMetric | `cf:valuemetric`

In addition, logs from the Nozzle itself are of sourcetype `cf:splunknozzle`.

You can use these Splunk sourcetypes to search relevant events from the search bar in Splunk Search & Reporting Application. For example:

  * Search for any errors from your foundation:

    `sourcetype=cf:error`

  * Search for router bad gateways:

    `sourcetype=cf:counterevent name="bad_gateways"`

  * Search for metrics of remaining cell disk capacity or memory:

    `sourcetype=cf:valuemetric name=CapacityRemainingDisk`
    `sourcetype=cf:valuemetric name=CapacityRemainingMemory`

Search is the primary way users navigate data in Splunk Enterprise. You can write a search to retrieve events from an index, use statistical commands to calculate metrics and generate reports, search for specific conditions within a rolling time window, identify patterns in your data, predict future trends, and so on. Searches can be saved as reports and used to power dashboard panels, as covered in next section.

##<a id='report'></a>Report & Visualize Firehose Data

To monitor your environment operational health, you can build on these same searches to generate reports & visualizations. For example:

  * Report available memory per cell:

    ```
    sourcetype=cf:valuemetric name=CapacityRemainingMemory
      | eval valueGB=round(case(unit=="MiB", value/1024, unit=="KiB", value/(1024*1024), unit=="GiB", value),2)
      | stats min(valueGB) as mem by job_instance
      | rename mem as "Available Memory (GB)", job_instance as "Job Instance"
    ```
    ![Report Example: Available mem per cell](images/report-available-memory-per-cell.png)

  * Report available memory per cell over time:

    ```
    sourcetype=cf:valuemetric name=CapacityRemainingMemory 
      | eval valueGB=round(case(unit=="MiB", value/1024, unit=="KiB", value/(1024*1024), unit=="GiB", value),2) 
      | timechart min(valueGB) by job_instance
    ```
    ![Report Example: Available mem per cell over time](images/report-available-memory-per-cell-over-time.png)

  * Report number of routes registered with trend indicator:

    ```
    sourcetype=cf:valuemetric name=RoutesTotal
      | timechart avg(value) as numRoutes
    ```
    ![Report Example: Total routes with trend](images/report-routes-total-with-trend.png)

To learn more about searching & reporting with Splunk, refer [here](https://docs.splunk.com/Documentation/Splunk) for complete list of manuals, from generating visualizations to creating alerts.

##<a id='add-on'></a>Use Splunk Add-on for Cloud Foundry

![Report Example: Sample Ops Dashboard](images/dashboard-sample-cloud-foundry-add-on.png)

##<a id='troubleshooting'></a> Advanced Troubleshooting

#### <a id='architecture'></a> Architecture Overview

Before troubleshooting it's useful to understand exactly what the tile installs.
Each vm contains two jobs:

* **splunk-nozzle**: This job is a small application that listens to the Cloud Foundry
[Loggregator's firehose](https://github.com/cloudfoundry/loggregator). When configured
to, the nozzle will also connect back to the Cloud Foundry API to collect and cache application metadata
(enriching events with additional information).
* **splunk-forwarder**: This job is a Splunk
[heavy forwarder](https://docs.splunk.com/Splexicon:Heavyforwarder). It sets up a local
[HTTP event collector](http://dev.splunk.com/view/event-collector/SP-CAAAE6M) to
receive events from the nozzle and then sends them on to the user-specified pre-configured indexer(s).

The logging system will round-robin events across the `splunk-nozzle` vm instances. Each
`splunk-nozzle` job will send the events it received locally to the
co-loated `splunk-forwarder`.

#### <a id='walkthrough'></a> Troubleshooting Walkthrough

The pre-requisite to trouble shooting the Nozzle is
[connecting to the PCF deployment's bosh](http://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html)

Having done that, the [bosh logs](https://bosh.io/docs/job-logs.html)
command is a useful place to start debugging.

```
bosh logs splunk-nozzle 0
```

This will download a local copy of the nozzle's logs and the control script that starts
the Splunk forwarder deamon. This could illuminate issues. For example, seeing

```
goroutine 28 [running]:
...
panic: Non-ok response code [503] from splunk: {"text":"Server is busy","code":9}
...
```

would point an operator toward failure in the communication between the nozzle and
its co-located Splunk forwarder.

To view the Splunk forwarder's logs, look through
`/var/vcap/packages/splunk/var/log` on the nozzle's vms.

**todo Roy: add some useful info/links to debugging a Splunk forwarder**

```
sourcetype="cf:splunknozzle" data.error=*
```